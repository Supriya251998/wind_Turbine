{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/supriyasindigerekumaraswmamy/Desktop/Thesis/wind_Turbine/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import learning_curve, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = pd.read_csv('../data/model_data/failures.csv',sep=',')\n",
    "components = failures['Component'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "for component in components:\n",
    "    globals()[f\"{component}_df\"] = pd.read_csv(f'../data/model_data/labelled_data_{component}.csv',sep=',')\n",
    "    globals()[f\"{component}_df\"]['Turbine_ID'] = encoder.fit_transform(['Turbine_ID']*globals()[f\"{component}_df\"].shape[0])\n",
    "    # set the date as the index\n",
    "    globals()[f\"{component}_df\"] = globals()[f\"{component}_df\"].set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_target_name = \"Failure (Target)\"\n",
    "for component in components:\n",
    "    X = globals()[f\"{component}_df\"].drop(columns=['Component',class_target_name])\n",
    "    y = globals()[f\"{component}_df\"][class_target_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    globals()[f\"{component}_X_train\"] = X_train\n",
    "    globals()[f\"{component}_X_test\"] = X_test\n",
    "    globals()[f\"{component}_y_train\"] = y_train\n",
    "    globals()[f\"{component}_y_test\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: review the links mentioned above for guidance on connecting to a managed tracking server, such as the free Databricks Community Edition\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment with ID: 374465840103549388\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"Predictive Maintenance\"\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "print(f\"Created experiment with ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override Optuna's default logging to ERROR only\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# define a logging callback that will report on only new challenger parameter configurations if a\n",
    "# trial has usurped the state of 'best conditions'\n",
    "\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    \"\"\"\n",
    "    Logging callback that will report when a new trial iteration improves upon existing\n",
    "    best trial values.\n",
    "\n",
    "    Note: This callback is not intended for use in distributed computing systems such as Spark\n",
    "    or Ray due to the micro-batch iterative implementation for distributing trials to a cluster's\n",
    "    workers or agents.\n",
    "    The race conditions with file system state management for distributed trials will render\n",
    "    inconsistent values with this callback.\n",
    "    \"\"\"\n",
    "\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a objective funtion for the Optuna study for each component\n",
    "def objective(trial, component):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna study to optimize hyperparameters for the XGBoost classifier\n",
    "    \"\"\"\n",
    "\n",
    "    # define the search space for the hyperparameters\n",
    "    search_space = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [50, 100, 200]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10, 20, 40, 80]),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'subsample': 1.0,\n",
    "        'colsample_bytree': 1.0,\n",
    "        'lambda': 1.0,\n",
    "        'alpha': 1.0,\n",
    "        'max_features': trial.suggest_int('max_features', 5, 50)\n",
    "    }\n",
    "\n",
    "    # create the XGBoost classifier with the hyperparameters\n",
    "    model = XGBClassifier(**search_space)\n",
    "    model.fit(globals()[f\"{component}_X_train\"], globals()[f\"{component}_y_train\"])\n",
    "    # apply feature selection\n",
    "    selector = SelectFromModel(model, threshold=-np.inf, max_features=search_space['max_features'])\n",
    "    X_train_selected = selector.transform(globals()[f\"{component}_X_train\"])\n",
    "    X_test_selected = selector.transform(globals()[f\"{component}_X_test\"])\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    pipeline = Pipeline([(\"model\", model)])\n",
    "\n",
    "    # evaluate the model with cross-validation\n",
    "    score = cross_val_score(\n",
    "        pipeline, globals()[f\"{component}_X_train\"], globals()[f\"{component}_y_train\"], cv=5\n",
    "    ).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trial 0 achieved value: 0.9530791788856305\n",
      "Trial 2 achieved value: 0.9583577712609971 with  0.5508% improvement\n",
      "Best score for GEARBOX component: 0.9583577712609971\n",
      "Best parameters for GEARBOX component: {'n_estimators': 200, 'max_depth': 80, 'learning_rate': 0.05439579553639034, 'max_features': 8}\n",
      "Initial trial 0 achieved value: 0.901466275659824\n",
      "Trial 1 achieved value: 0.9061583577712609 with  0.5178% improvement\n",
      "Trial 2 achieved value: 0.9073313782991201 with  0.1293% improvement\n",
      "Best score for GENERATOR component: 0.9073313782991201\n",
      "Best parameters for GENERATOR component: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.10845720027446801, 'max_features': 31}\n",
      "Initial trial 0 achieved value: 0.8627565982404691\n",
      "Best score for HYDRAULIC_GROUP component: 0.8627565982404691\n",
      "Best parameters for HYDRAULIC_GROUP component: {'n_estimators': 50, 'max_depth': 40, 'learning_rate': 0.07098441477305667, 'max_features': 49}\n",
      "Initial trial 0 achieved value: 0.9624633431085045\n",
      "Trial 3 achieved value: 0.9642228739002933 with  0.1825% improvement\n",
      "Best score for GENERATOR_BEARING component: 0.9642228739002933\n",
      "Best parameters for GENERATOR_BEARING component: {'n_estimators': 50, 'max_depth': 40, 'learning_rate': 0.12737281567443362, 'max_features': 49}\n",
      "Initial trial 0 achieved value: 0.9542521994134898\n",
      "Trial 1 achieved value: 0.9565982404692083 with  0.2452% improvement\n",
      "Trial 2 achieved value: 0.9571847507331379 with  0.0613% improvement\n",
      "Best score for TRANSFORMER component: 0.9571847507331379\n",
      "Best parameters for TRANSFORMER component: {'n_estimators': 100, 'max_depth': 20, 'learning_rate': 0.1425855341118972, 'max_features': 48}\n"
     ]
    }
   ],
   "source": [
    "# create a study for each component\n",
    "mlflow.set_experiment(experiment_name)\n",
    "for component in components:\n",
    "    globals()[f\"{component}_study\"] = optuna.create_study(direction='maximize')\n",
    "    globals()[f\"{component}_study\"].optimize(lambda trial: objective(trial, component), n_trials=5, callbacks=[champion_callback])\n",
    "\n",
    "    # get the best hyperparameters\n",
    "    best_params = globals()[f\"{component}_study\"].best_params\n",
    "    best_score = globals()[f\"{component}_study\"].best_value\n",
    "    print(f\"Best score for {component} component: {best_score}\")\n",
    "    print(f\"Best parameters for {component} component: {best_params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the best model and parameters and the best score to ml flow for each component\n",
    "for component in components:\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=component):\n",
    "        mlflow.log_params( globals()[f\"{component}_study\"].best_params)\n",
    "        mlflow.log_metrics({'score': globals()[f\"{component}_study\"].best_value})\n",
    "    \n",
    "        mlflow.set_tags(\n",
    "            tags={\n",
    "            \"project\": \"Thesis\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "            \"component\": component\n",
    "         }\n",
    "        )\n",
    "        globals()[f\"{component}_best_model\"]= XGBClassifier(**globals()[f\"{component}_study\"].best_params)\n",
    "        globals()[f\"{component}_best_model\"].fit(globals()[f\"{component}_X_train\"], globals()[f\"{component}_y_train\"])\n",
    "   \n",
    "\n",
    "        artifact_path = \"model\"\n",
    "\n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb_model= globals()[f\"{component}_best_model\"],\n",
    "            artifact_path=artifact_path,\n",
    "        #input_example= GEARBOX_X_train.iloc[[0]],\n",
    "            model_format='pickle',\n",
    "            metadata={\"model_data_version\": 1},\n",
    "        )\n",
    "\n",
    "        model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models to disk\n",
    "if not os.path.exists('../models_MLFLOW'):\n",
    "    os.makedirs('../models_MLFLOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"xgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for component in components:\n",
    "    with open('./models_MLFLOW/selected-{}.pickle'.format(component), 'wb') as handle:\n",
    "        pickle.dump(globals()[f\"{component}_best_model\"], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
