{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/supriyasindigerekumaraswmamy/Desktop/Thesis/wind_Turbine/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import learning_curve, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('/Users/supriyasindigerekumaraswmamy/Desktop/Thesis/wind_Turbine'))\n",
    "\n",
    "from utils.helper import *\n",
    "failures = load_failures_data('../data/model_data/failures.csv')\n",
    "components = failures['component'].unique()\n",
    "component_data = load_all_component_data(components)\n",
    "data_splits = prepare_all_data_for_training(component_data, \"target_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. data_splits[component][0] : Component_X_train\n",
    "2. data_splits[component][1] : Component_X_test\n",
    "3. data_splits[component][2] : Component_y_train\n",
    "4. data_splits[component][3] : Component_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: review the links mentioned above for guidance on connecting to a managed tracking server, such as the free Databricks Community Edition\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:80\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment with ID: 5\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"XAI\"\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "print(f\"Created experiment with ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override Optuna's default logging to ERROR only\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# define a logging callback that will report on only new challenger parameter configurations if a\n",
    "# trial has usurped the state of 'best conditions'\n",
    "\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    \"\"\"\n",
    "    Logging callback that will report when a new trial iteration improves upon existing\n",
    "    best trial values.\n",
    "\n",
    "    Note: This callback is not intended for use in distributed computing systems such as Spark\n",
    "    or Ray due to the micro-batch iterative implementation for distributing trials to a cluster's\n",
    "    workers or agents.\n",
    "    The race conditions with file system state management for distributed trials will render\n",
    "    inconsistent values with this callback.\n",
    "    \"\"\"\n",
    "\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a objective funtion for the Optuna study for each component\n",
    "def objective(trial, component):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna study to optimize hyperparameters for the XGBoost classifier\n",
    "    \"\"\"\n",
    "\n",
    "    # define the search space for the hyperparameters\n",
    "    search_space = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [50, 100, 200]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10, 20, 40, 80]),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'subsample': 1.0,\n",
    "        'colsample_bytree': 1.0,\n",
    "        'lambda': 1.0,\n",
    "        'alpha': 1.0,\n",
    "        'max_features': trial.suggest_int('max_features', 5, 20)\n",
    "    }\n",
    "\n",
    "    # create the XGBoost classifier with the hyperparameters\n",
    "    model = XGBClassifier(**search_space)\n",
    "    model.fit(data_splits[component][0], data_splits[component][2])\n",
    "    # apply feature selection\n",
    "    selector = SelectFromModel(model, threshold=-np.inf, max_features=search_space['max_features'])\n",
    "    X_train_selected = selector.transform(data_splits[component][0])\n",
    "    X_test_selected = selector.transform(data_splits[component][1])\n",
    "    model.fit(X_train_selected, data_splits[component][2])\n",
    "    \n",
    "    pipeline = Pipeline([(\"model\", model)])\n",
    "\n",
    "    # evaluate the model with cross-validation\n",
    "    score = cross_val_score(\n",
    "        pipeline, data_splits[component][0], data_splits[component][2], cv=5\n",
    "    ).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trial 0 achieved value: 0.9540603852160332\n",
      "Trial 1 achieved value: 0.95760194343224 with  0.3698% improvement\n",
      "Best score for GEARBOX component: 0.95760194343224\n",
      "Best parameters for GEARBOX component: {'n_estimators': 100, 'max_depth': 80, 'learning_rate': 0.07735647047260169, 'max_features': 13}\n",
      "Initial trial 0 achieved value: 0.9104771820232518\n",
      "Trial 1 achieved value: 0.9116571230262016 with  0.1294% improvement\n",
      "Trial 4 achieved value: 0.9128405344438659 with  0.1296% improvement\n",
      "Best score for GENERATOR component: 0.9128405344438659\n",
      "Best parameters for GENERATOR component: {'n_estimators': 100, 'max_depth': 40, 'learning_rate': 0.06382497465228437, 'max_features': 20}\n",
      "Initial trial 0 achieved value: 0.8616050668054832\n",
      "Trial 2 achieved value: 0.8627798021863613 with  0.1362% improvement\n",
      "Trial 4 achieved value: 0.865139684192261 with  0.2728% improvement\n",
      "Best score for HYDRAULIC_GROUP component: 0.865139684192261\n",
      "Best parameters for HYDRAULIC_GROUP component: {'n_estimators': 50, 'max_depth': 20, 'learning_rate': 0.15908373090003225, 'max_features': 20}\n",
      "Initial trial 0 achieved value: 0.9628960610792989\n",
      "Trial 1 achieved value: 0.965842443171959 with  0.3051% improvement\n",
      "Trial 4 achieved value: 0.9664341488807912 with  0.0612% improvement\n",
      "Best score for GENERATOR_BEARING component: 0.9664341488807912\n",
      "Best parameters for GENERATOR_BEARING component: {'n_estimators': 200, 'max_depth': 40, 'learning_rate': 0.053365506878406785, 'max_features': 15}\n",
      "Initial trial 0 achieved value: 0.9522991497483948\n",
      "Best score for TRANSFORMER component: 0.9522991497483948\n",
      "Best parameters for TRANSFORMER component: {'n_estimators': 200, 'max_depth': 80, 'learning_rate': 0.04105289138285317, 'max_features': 17}\n"
     ]
    }
   ],
   "source": [
    "# create a study for each component\n",
    "mlflow.set_experiment(experiment_name)\n",
    "trials= 5\n",
    "for component in components:\n",
    "    globals()[f\"{component}_study\"] = optuna.create_study(direction='maximize')\n",
    "    globals()[f\"{component}_study\"].optimize(lambda trial: objective(trial, component), n_trials=trials, callbacks=[champion_callback])\n",
    "\n",
    "    # get the best hyperparameters\n",
    "    best_params = globals()[f\"{component}_study\"].best_params\n",
    "    best_score = globals()[f\"{component}_study\"].best_value\n",
    "    print(f\"Best score for {component} component: {best_score}\")\n",
    "    print(f\"Best parameters for {component} component: {best_params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the best model and parameters and the best score to ml flow for each component\n",
    "for component in components:\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=component):\n",
    "        mlflow.log_params( globals()[f\"{component}_study\"].best_params)\n",
    "        mlflow.log_metrics({'score': globals()[f\"{component}_study\"].best_value})\n",
    "    \n",
    "        mlflow.set_tags(\n",
    "            tags={\n",
    "            \"project\": \"Thesis\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "            \"component\": component\n",
    "         }\n",
    "        )\n",
    "        globals()[f\"{component}_best_model\"]= XGBClassifier(**globals()[f\"{component}_study\"].best_params)\n",
    "        globals()[f\"{component}_best_model\"].fit(data_splits[component][0], data_splits[component][2])\n",
    "   \n",
    "\n",
    "        artifact_path = \"model\"\n",
    "\n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb_model= globals()[f\"{component}_best_model\"],\n",
    "            artifact_path=artifact_path,\n",
    "        #input_example= GEARBOX_X_train.iloc[[0]],\n",
    "            model_format='pickle',\n",
    "            metadata={\"model_data_version\": 1},\n",
    "        )\n",
    "\n",
    "        model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models to disk\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"xgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for component in components:\n",
    "    with open('./models/selected-{}.pickle'.format(component), 'wb') as handle:\n",
    "        pickle.dump(globals()[f\"{component}_best_model\"], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
